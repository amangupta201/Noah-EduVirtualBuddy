import requests
import logging
from config import OPENAI_API_KEY, OPENAI_MODEL

# Set up a dedicated logger that does NOT propagate to root logger
logger = logging.getLogger("rag_pipeline_logger")
logger.setLevel(logging.INFO)
logger.propagate = False  # This is the key line

# Add handler only if it doesn't exist
if not logger.handlers:
    file_handler = logging.FileHandler('openairesponses.log')
    formatter = logging.Formatter('%(asctime)s - %(message)s')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)

class RAGPipeline:
    def __init__(self, embedder, vector_store):
        self.embedder = embedder
        self.vector_store = vector_store

    def ask(self, question):
        """
        Generate a response to a question using RAG.

        Args:
            question (str): User question.

        Returns:
            str: Model-generated answer.
        """
        query_embedding = self.embedder.encode([question])
        logger.info("Embedding: Generated embedding for the question.")

        relevant_chunks = self.vector_store.search(query_embedding, k=5)
        logger.info("Vector store: Retrieved top 5 relevant chunks.")

        context = "\n\n".join(relevant_chunks)
        prompt = f"Use the context below to answer the question.\n\nContext:\n{context}\n\nQuestion: {question}"
        logger.info("Prompt sent to OpenAI:\n%s", prompt)

        payload = {
            "model": OPENAI_MODEL,
            "messages": [{"role": "user", "content": prompt}]
        }
        headers = {
            "Authorization": f"Bearer {OPENAI_API_KEY}",
            "Content-Type": "application/json",
        }

        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers=headers,
            json=payload,
        )
        response.raise_for_status()

        raw_response = response.json()
        logger.info("Raw response from OpenAI:\n%s", raw_response)

        answer = raw_response["choices"][0]["message"]["content"].strip()
        logger.info("Final answer generated by OpenAI:\n%s", answer)

        return answer
